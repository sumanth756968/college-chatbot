{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "c4ffccb0-7654-45e8-82f4-731db9bbdf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "FAQ_INDEX_PATH = \"faq_index.faiss\"\n",
    "FAQ_META_PATH = \"faq_meta.pkl\"\n",
    "SITE_INDEX_PATH = \"site_index.faiss\"\n",
    "SITE_META_PATH = \"site_meta.pkl\"\n",
    "\n",
    "FAQ_THRESHOLD = 0.70\n",
    "SITE_THRESHOLD = 0.35\n",
    "\n",
    "# ---------------- LOAD MODELS ----------------\n",
    "@st.cache_resource\n",
    "def load_all():\n",
    "    embedder = SentenceTransformer(MODEL_NAME)\n",
    "    faq_index = faiss.read_index(FAQ_INDEX_PATH)\n",
    "    with open(FAQ_META_PATH, \"rb\") as f:\n",
    "        faq_meta = pickle.load(f)\n",
    "\n",
    "    site_index = faiss.read_index(SITE_INDEX_PATH)\n",
    "    with open(SITE_META_PATH, \"rb\") as f:\n",
    "        site_meta = pickle.load(f)\n",
    "\n",
    "    generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
    "    return embedder, faq_index, faq_meta, site_index, site_meta, generator\n",
    "\n",
    "embedder, faq_index, faq_meta, site_index, site_meta, generator = load_all()\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def l2_normalize(vecs):\n",
    "    norms = np.linalg.norm(vecs, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    return vecs / norms\n",
    "\n",
    "def retrieve_context(query, top_k=3):\n",
    "    q = query.strip().lower()\n",
    "    q_emb = embedder.encode([q], convert_to_numpy=True)\n",
    "    q_emb = l2_normalize(q_emb.astype(\"float32\"))\n",
    "\n",
    "    # FAQ search\n",
    "    D, I = faq_index.search(q_emb, top_k)\n",
    "    if I[0][0] != -1 and D[0][0] >= FAQ_THRESHOLD:\n",
    "        best_idx = I[0][0]\n",
    "        return {\n",
    "            \"source\": \"faq\",\n",
    "            \"context\": faq_meta[\"answers\"][best_idx],\n",
    "            \"meta\": {\"question\": faq_meta[\"questions\"][best_idx],\n",
    "                     \"intent\": faq_meta[\"intents\"][best_idx],\n",
    "                     \"score\": float(D[0][0])}\n",
    "        }\n",
    "\n",
    "    # Site search\n",
    "    D, I = site_index.search(q_emb, top_k)\n",
    "    if I[0][0] != -1 and D[0][0] >= SITE_THRESHOLD:\n",
    "        best_idx = I[0][0]\n",
    "        chunk = site_meta[\"chunks\"][best_idx]\n",
    "        return {\n",
    "            \"source\": \"site\",\n",
    "            \"context\": chunk[\"text\"],\n",
    "            \"meta\": {\"url\": chunk[\"url\"], \"score\": float(D[0][0])}\n",
    "        }\n",
    "\n",
    "    return {\"source\": \"none\", \"context\": None, \"meta\": {}}\n",
    "\n",
    "def generate_answer(user_query, context):\n",
    "    if not context:\n",
    "        return \"Sorry, I couldnâ€™t find relevant information.\"\n",
    "    prompt = f\"Answer the question below using the given context.\\n\\nQuestion: {user_query}\\nContext: {context}\\nAnswer:\"\n",
    "    result = generator(prompt, max_length=200, temperature=0.4)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# ---------------- STREAMLIT UI ----------------\n",
    "st.title(\"ðŸŽ“ College FAQ + Website Chatbot\")\n",
    "st.write(\"Ask me anything about the college. Iâ€™ll first check FAQ, then the website.\")\n",
    "\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "\n",
    "user_query = st.text_input(\"Your Question:\")\n",
    "\n",
    "if user_query:\n",
    "    result = retrieve_context(user_query)\n",
    "    answer = generate_answer(user_query, result[\"context\"])\n",
    "    st.session_state.history.append((\"You\", user_query))\n",
    "    st.session_state.history.append((\"Bot\", answer))\n",
    "\n",
    "for role, msg in st.session_state.history:\n",
    "    if role == \"You\":\n",
    "        st.markdown(f\"**You:** {msg}\")\n",
    "    else:\n",
    "        st.markdown(f\"**Bot:** {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "45b0c690-9b9b-43f4-ae52-e1e9ad95d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
